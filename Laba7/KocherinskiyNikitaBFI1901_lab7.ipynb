{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b562eb4b",
   "metadata": {},
   "source": [
    "# Лабораторная работа No 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ff73a",
   "metadata": {},
   "source": [
    "## Классификация обзоров фильмов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8b42c",
   "metadata": {},
   "source": [
    "### Цель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eda925",
   "metadata": {},
   "source": [
    "Классификация последовательностей - это проблема прогнозирующего моделирования,\n",
    "когда у вас есть некоторая последовательность входных данных в пространстве или\n",
    "времени, и задача состоит в том, чтобы предсказать категорию для последовательности.\n",
    "Проблема усложняется тем, что последовательности могут различаться по длине,\n",
    "состоять из очень большого словарного запаса входных символов и могут потребовать от\n",
    "модели изучения долгосрочного контекста или зависимостей между символами во входной\n",
    "последовательности.\n",
    "В данной лабораторной работе также будет использоваться датасет IMDb, однако\n",
    "обучение будет проводиться с помощью рекуррентной нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23fa84",
   "metadata": {},
   "source": [
    "### Задачи\n",
    "\n",
    "1. Ознакомиться с рекуррентными нейронными сетями\n",
    "2. Изучить способы классификации текста\n",
    "3. Ознакомиться с ансамблированием сетей\n",
    "4. Построить ансамбль сетей, который позволит получать точность не менее 97%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d857af",
   "metadata": {},
   "source": [
    "### Требования\n",
    "1. Найти набор оптимальных ИНС для классификации текста\n",
    "2. Провести ансамблирование моделей\n",
    "3. Написать функцию/функции, которые позволят загружать текст и получать результат ансамбля сетей\n",
    "4. Провести тестирование сетей на своих текстах (привести в отчете)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d6b36",
   "metadata": {},
   "source": [
    "### Выполнение работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee961b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "391/391 [==============================] - 277s 702ms/step - loss: 0.4688 - accuracy: 0.7703 - val_loss: 0.3941 - val_accuracy: 0.8381\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 267s 684ms/step - loss: 0.3454 - accuracy: 0.8532 - val_loss: 0.4189 - val_accuracy: 0.8171\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 267s 684ms/step - loss: 0.2683 - accuracy: 0.8930 - val_loss: 0.3209 - val_accuracy: 0.8739\n",
      "Accuracy: 87.39%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774daa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length,\n",
    "input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
